# Ollama-FastAPI-LlamaIndex
### Comes with Streamlit-UI
---

### Client: 
>* STEP 1 : Request Query from User
>* STEP 2 : Send Query to Server
>* STEP 3 : Receive Response from Server
>* STEP 4 : Display Response to User

### Server: 
>* STEP 1 : Receive Query from Client
>* STEP 2 : Send Query to Ollama
>* STEP 3 : Receive Response from Ollama
>* STEP 4 : Send Response to Client

---

### Tested On: 
>* Client &nbsp;: MacBook Pro 14"
>* Server : RTX 3060 12G || Ubuntu Server 24.04 LTS
>* LLM &nbsp;&nbsp;&nbsp;&nbsp;: Meta-Llama-3-8B